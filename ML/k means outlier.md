روش‌های شناسایی داده‌های پرت (Outlier) در الگوریتم K-Means
۱. مقدمه

الگوریتم K-Means یکی از رایج‌ترین الگوریتم‌های خوشه‌بندی است، اما نسبت به وجود داده‌های پرت حساسیت بالایی دارد. حضور Outlierها می‌تواند باعث تغییر مکان مراکز خوشه‌ها شده و دقت و کیفیت خوشه‌بندی را کاهش دهد. از این رو، شناسایی داده‌های پرت در فرآیند K-Means از اهمیت بالایی برخوردار است.

۲. تعریف داده پرت

داده پرت به نقطه‌ای اطلاق می‌شود که:

فاصله قابل توجهی از مرکز خوشه خود دارد

با الگوی کلی توزیع داده‌ها سازگار نیست

ممکن است در اثر نویز، خطای اندازه‌گیری یا رفتار غیرمعمول ایجاد شده باشد

۳. استفاده از فاصله تا مرکز خوشه (روش مبتنی بر فاصله)
ایده اصلی

در الگوریتم K-Means، هر داده به نزدیک‌ترین مرکز خوشه اختصاص داده می‌شود. اگر فاصله یک داده از مرکز خوشه‌اش زیاد باشد، می‌توان آن را به‌عنوان یک داده پرت در نظر گرفت.

بیان ریاضی

اگر:

xi
x
i
	​

 یک نمونه داده

μk
μ
k
	​

 مرکز خوشه مربوطه

فاصله اقلیدسی به صورت زیر تعریف می‌شود:

d(xi,μk)=∣xi−μk∣
d(x
i
	​

,μ
k
	​

)=∣x
i
	​

−μ
k
	​

∣

نقاطی که فاصله آن‌ها از یک مقدار آستانه مشخص فراتر رود، به‌عنوان Outlier شناسایی می‌شوند.

۴. استفاده از توزیع آماری فاصله‌ها (آستانه آماری)

در این روش:

فاصله تمام داده‌ها از مراکز خوشه محاسبه می‌شود

میانگین و انحراف معیار این فاصله‌ها تعیین می‌گردد

اگر شرط زیر برقرار باشد:

d(xi,μk)>μd+ασd
d(x
i
	​

,μ
k
	​

)>μ
d
	​

+ασ
d
	​


آنگاه داده 
xi
x
i
	​

 به‌عنوان داده پرت در نظر گرفته می‌شود.

معمولاً مقدار 
α
α بین ۲ تا ۳ انتخاب می‌شود.

۵. استفاده از مجموع مربعات فاصله‌ها (SSD)

الگوریتم K-Means با کمینه‌سازی تابع هزینه زیر آموزش می‌بیند:

J=∑i=1n∣xi−μci∣2
J=
i=1
∑
n
	​

∣x
i
	​

−μ
c
i
	​

	​

∣
2

نقاطی که سهم بزرگی در مقدار این تابع دارند:

اثر نامتعارفی روی مدل می‌گذارند

می‌توانند به‌عنوان داده‌های پرت شناسایی شوند

۶. بررسی اندازه خوشه‌ها (تشخیص خوشه‌های کوچک)

در برخی موارد، داده‌های پرت:

یک خوشه بسیار کوچک یا حتی تک‌عضوی تشکیل می‌دهند

در این شرایط:

خوشه‌هایی با تعداد اعضای بسیار کم

به‌عنوان خوشه‌های پرت در نظر گرفته می‌شوند

این روش به‌ویژه در مجموعه‌داده‌های بزرگ کاربردی است.

۷. استفاده از ضریب Silhouette برای نقاط منفرد

ضریب سیلوئت برای هر داده به‌صورت زیر تعریف می‌شود:

s(i)=b(i)−a(i)max⁡(a(i),b(i))
s(i)=
max(a(i),b(i))
b(i)−a(i)
	​


که در آن:

a(i)
a(i): میانگین فاصله داده با سایر نقاط خوشه خودش

b(i)
b(i): کمترین میانگین فاصله داده با خوشه‌های دیگر

تفسیر مقادیر:

نزدیک به -1 → احتمال داده پرت

نزدیک به 0 → قرارگیری روی مرز خوشه‌ها

نزدیک به 1 → خوشه‌بندی مناسب

۸. محدودیت‌های K-Means در شناسایی داده‌های پرت

فرض کروی بودن شکل خوشه‌ها

حساسیت زیاد به نویز و داده‌های پرت

نیاز به تعیین تعداد خوشه‌ها پیش از اجرا

به همین دلیل، K-Means ذاتاً یک الگوریتم تشخیص Outlier محسوب نمی‌شود.

۹. راهکارهای بهبود عملکرد

حذف داده‌های پرت پیش از اجرای K-Means

استفاده از الگوریتم‌های مقاوم‌تر مانند:

DBSCAN

Isolation Forest

جایگزینی K-Means با K-Medoids

۱۰. جمع‌بندی نهایی

فاصله از مرکز خوشه مهم‌ترین معیار شناسایی Outlier در K-Means است

داده‌های پرت باعث جابه‌جایی مراکز خوشه می‌شوند

K-Means ابزار مستقیمی برای تشخیص Outlier ندارد

شناسایی داده‌های پرت معمولاً به‌صورت غیرمستقیم انجام می‌گیرد
